# SmartExam Compiler

## AI-Driven Question Paper Analyzer

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/)
[![Flask](https://img.shields.io/badge/Flask-3.0+-lightgrey.svg)](https://flask.palletsprojects.com/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.100+-green.svg)](https://fastapi.tiangolo.com/)


A comprehensive compiler design project that automates the analysis and validation of academic question papers using AI-powered OCR, custom DSL parsing, and semantic analysis.

## ğŸ¯ Problem Statement

Creating question papers for exams is still largely manual. Teachers and academic staff type questions into Word or LaTeX, tally marks in their heads, and try to ensure syllabus coverage, balance of difficulty, and correctness of answer keys. This manual process is error-prone:

- Totals don't always add up to the declared marks
- Questions are sometimes repeated or skipped
- Topics may be over- or under-represented
- MCQs occasionally have more than one correct answer
- Answer keys can be missing or inconsistent
- The estimated time to solve a paper doesn't always match the scheduled exam duration

These mistakes cause confusion, unfair assessments, and rework. They waste time for staff and hurt students' trust in exams.

There is no easy way to validate a paper before it goes live, especially across multiple departments and campuses. Existing quiz platforms focus on delivery, not on checking the content.

## ğŸš€ Proposed Solution

We propose building a Question Paper Compiler â€” a software tool, based on Lex and Yacc, that takes a structured text representation of an exam paper and "compiles" it: parsing, validating, and reporting on its quality, just like a compiler does for source code.

The core of the system is a simple domain-specific language (DSL) for exams. For example:

```
Exam: Compiler Design Midterm
TotalMarks: 50
Duration: 90 min
Syllabus: Lexical Analysis, Parsing, Semantics

Q1 [MCQ] (2 marks) Topic: Lexical Analysis Difficulty: Easy
Correct: b
Options:
a. Regular expressions are ...
b. DFA accepts only ...
c. NFA requires ...
d. Compiler back-end is ...
---

Q2 [Short] (5 marks) Topic: Parsing Difficulty: Medium
Correct: Any valid example of LL(1) grammar
---
```

The compiler will:

- **Lexical Analysis**: Break the text into tokens (Exam title, questions, options, marks, etc.)
- **Parsing**: Check that the paper follows the DSL grammar (correct ordering, fields present, syntax valid)
- **Semantic Analysis**: Apply academic rules, for example:
  - Ensure marks add up to the declared total
  - Ensure all syllabus topics are covered
  - Ensure difficulty distribution meets set ratios
  - Flag duplicate or near-duplicate questions
  - Validate MCQs have a single correct option
  - Check the sum of estimated times fits within the declared exam duration
- **Reporting**: Produce a human-readable report with errors, warnings, and summaries

## âœ¨ Screenshots
!(static/images/upload_page.png)
### Upload Page
![Upload Page](static/images/dashboard_overview.png)
*The main interface for uploading question papers and syllabus files*

### Dashboard Overview
![Dashboard Overview](static/images/dashboard_charts.png)
*Comprehensive analysis dashboard showing question paper statistics and validation results*

### Analysis Charts
![Analysis Charts](static/images/lexical_analysis.png)
![](static/images/parse_tree.png)
*Interactive charts displaying difficulty distribution, marks breakdown, and time analysis*

### Lexical Analysis
![Lexical Analysis](static/images/Lexical_analyser.png)
*Token analysis view showing the lexical breakdown of the processed question paper*

### Parse Tree Visualization
![Parse Tree](static/images/Parse_tree_view.png)
*Abstract Syntax Tree (AST) visualization of the parsed question paper structure*

### Enhanced Paper Generation
![Enhanced Paper](static/images/enhanced_paper.png)
![](static/images/api_docs.png)
*AI-generated enhanced question paper with improved clarity and balance*



## âœ¨ Features

### Core Functionality
- **OCR Text Extraction**: Powered by Google Vision API for accurate text extraction from PDFs and images
- **AI-Powered Preprocessing**: Intelligent text cleaning and formatting using NLP techniques
- **Custom DSL Compiler**: Lex/Yacc-based parser for question paper validation
- **Semantic Analysis**: Comprehensive academic rule checking and quality assessment
- **Enhanced Paper Generation**: AI-driven suggestions for improved question papers
- **Web Dashboard**: Modern Flask-based UI with interactive visualizations
- **REST API**: FastAPI endpoints for programmatic access

### Analysis Capabilities
- Question validation and error detection
- Marks calculation and verification
- Difficulty distribution analysis
- Syllabus coverage assessment
- Time estimation and validation
- Duplicate question detection
- Crispness analysis for question clarity

### Output Formats
- Interactive web dashboard with charts
- JSON reports for semantic analysis
- PDF reports with visualizations
- Enhanced question paper generation
- Parse tree visualization (AST)
- Token analysis display

## ğŸ—ï¸ Architecture

The system follows a **Controller-Worker** architecture with multiple processing phases:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Web Interface â”‚    â”‚     REST API    â”‚    â”‚   File Upload   â”‚
â”‚    (Flask)      â”‚    â”‚   (FastAPI)     â”‚    â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   Phase 0: OCR &    â”‚
                    â”‚   Preprocessing     â”‚
                    â”‚ - Google Vision API â”‚
                    â”‚ - Text Cleaning     â”‚
                    â”‚ - DSL Formatting    â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   Phases 1-6:       â”‚
                    â”‚   Compilation       â”‚
                    â”‚ - Lexical Analysis  â”‚
                    â”‚ - Parsing           â”‚
                    â”‚ - Semantic Analysis â”‚
                    â”‚ - Code Generation   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   Phase 7: Reports  â”‚
                    â”‚ - Dashboard Data    â”‚
                    â”‚ - Enhanced Papers   â”‚
                    â”‚ - PDF Generation    â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Key Components

- **`app.py`**: Main Flask application with web routes
- **`analysis/`**: AI/ML processing modules (OCR, preprocessing, synthesis)
- **`compiler/`**: C/C++ compiler implementation (lexer, parser, semantic analysis)
- **`templates/`**: HTML templates for web interface
- **`static/`**: CSS, JavaScript, and assets
- **`jobs/`**: Processing job directories
- **`output/`**: Generated reports and files

## ğŸ“‹ Prerequisites

- Python 3.8+
- C/C++ compiler (GCC/Clang)
- Google Cloud Vision API credentials
- Tesseract OCR (optional fallback)
- Node.js (for additional tooling)

## ğŸš€ Installation

1. **Clone the repository:**
   ```bash
   git clone https://github.com/your-username/smartexam-compiler.git
   cd smartexam-compiler
   ```

2. **Install Python dependencies:**
   ```bash
   pip install -r requirements.txt
   ```

3. **Set up Google Cloud credentials:**
   - Obtain a Google Cloud service account key
   - Set the environment variable:
     ```bash
     export GOOGLE_APPLICATION_CREDENTIALS="path/to/your/service-account-key.json"
     ```
   - Or place the key file in `api key/` directory

4. **Configure Gemini AI:**
   ```bash
   export GEMINI_API_KEY="your-gemini-api-key"
   ```

5. **Build the C/C++ compiler:**
   ```bash
   cd compiler
   make
   cd ..
   ```

6. **Run setup scripts:**
   ```bash
   ./setup.sh
   ```

## ğŸ’» Usage

### Web Interface

1. **Start the Flask application:**
   ```bash
   python app.py
   ```

2. **Open your browser:**
   - Navigate to `http://localhost:5000`
   - Upload a question paper (PDF/image) and syllabus file
   - View analysis results in the interactive dashboard

### API Usage

1. **Start the FastAPI server:**
   ```bash
   uvicorn analysis.api:app --reload
   ```

2. **API Documentation:**
   - Interactive docs: `http://localhost:8000/docs`
   - Alternative docs: `http://localhost:8000/redoc`

### Command Line

```bash
# Run compiler directly
python compiler/q_compiler.py <job_directory>

# Test OCR extraction
python -c "from analysis.ocr_extract import extract_text_from_file; print(extract_text_from_file('path/to/file.pdf'))"
```

## ğŸ“š API Documentation

### Core Endpoints

#### OCR Extraction
```http
POST /extract-text/
```
Upload a file for text extraction using Google Vision API.

#### Full Pipeline Processing
```http
POST /process-paper/
```
Complete processing pipeline: OCR â†’ Preprocessing â†’ Compilation â†’ Enhanced Paper Generation.

#### Retrieve Results
```http
GET /job/{job_id}/enhanced-paper
GET /job/{job_id}/semantic-report
GET /job/{job_id}/dashboard
```

## ğŸ“ Project Structure

```
smartexam-compiler/
â”œâ”€â”€ analysis/                 # AI/ML processing modules
â”‚   â”œâ”€â”€ api.py               # FastAPI server
â”‚   â”œâ”€â”€ ocr_extract.py       # Google Vision OCR
â”‚   â”œâ”€â”€ preprocess.py        # Text cleaning & DSL formatting
â”‚   â”œâ”€â”€ synthesis.py         # Enhanced paper generation
â”‚   â”œâ”€â”€ semantic_analysis.py # Academic rule validation
â”‚   â””â”€â”€ ...
â”œâ”€â”€ compiler/                # C/C++ compiler implementation
â”‚   â”œâ”€â”€ lexer.l             # Lex specification
â”‚   â”œâ”€â”€ parser.y            # Yacc grammar
â”‚   â”œâ”€â”€ q_compiler.py       # Python wrapper
â”‚   â”œâ”€â”€ ast_helpers.c       # AST utilities
â”‚   â””â”€â”€ ...
â”œâ”€â”€ templates/              # HTML templates
â”‚   â”œâ”€â”€ index.html          # Main dashboard
â”‚   â”œâ”€â”€ upload.html         # File upload interface
â”‚   â”œâ”€â”€ dashboard.html      # Analysis results
â”‚   â””â”€â”€ ...
â”œâ”€â”€ static/                 # Web assets
â”‚   â”œâ”€â”€ images/             # Screenshots and assets
â”‚   â”œâ”€â”€ styles.css          # CSS stylesheets
â”‚   â”œâ”€â”€ scripts.js          # JavaScript files
â”‚   â””â”€â”€ ...
â”œâ”€â”€ jobs/                   # Processing job directories
â”œâ”€â”€ output/                 # Generated reports and files
â”œâ”€â”€ config/                 # Configuration files
â”œâ”€â”€ data/                   # Sample data and test files
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ app.py                  # Main Flask application
â”œâ”€â”€ setup.sh                # Setup script
â””â”€â”€ README.md               # This file
```

## ğŸ¤ Contributing

We welcome contributions! Please follow these steps:

1. Fork the repository
2. Create a feature branch: `git checkout -b feature/your-feature`
3. Commit your changes: `git commit -am 'Add your feature'`
4. Push to the branch: `git push origin feature/your-feature`
5. Submit a pull request

### Development Guidelines

- Follow PEP 8 for Python code
- Use meaningful commit messages
- Add tests for new features
- Update documentation as needed
- Ensure all tests pass before submitting

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- Google Cloud Vision API for OCR capabilities
- Google Generative AI (Gemini) for enhanced analysis
- Lex & Yacc for compiler foundation
- Flask and FastAPI communities

## ğŸ“ Support

For questions or issues:
- Open an issue on GitHub
- Check the documentation
- Review the TODO.md for current development status

---

*Empowering educators with automated question paper validation*

